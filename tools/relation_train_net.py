# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
"""
Basic training script for PyTorch
"""

# Set up custom environment before nearly anything else is imported
# NOTE: this should be the first import (no not reorder)
from logging import logProcesses
from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip

import argparse
import os
import json
import time
import datetime

import torch
from torch.nn.utils import clip_grad_norm_
from torch.utils.tensorboard import SummaryWriter

from maskrcnn_benchmark.config import cfg
from maskrcnn_benchmark.data import make_data_loader
from maskrcnn_benchmark.solver import make_lr_scheduler
from maskrcnn_benchmark.solver import make_optimizer
from maskrcnn_benchmark.engine.trainer import reduce_loss_dict
from maskrcnn_benchmark.engine.inference import inference
from maskrcnn_benchmark.modeling.detector import build_detection_model
from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer
from maskrcnn_benchmark.utils.checkpoint import clip_grad_norm
from maskrcnn_benchmark.utils.collect_env import collect_env_info
from maskrcnn_benchmark.utils.comm import synchronize, get_rank, all_gather
from maskrcnn_benchmark.utils.imports import import_file
from maskrcnn_benchmark.utils.logger import setup_logger, debug_print
from maskrcnn_benchmark.utils.miscellaneous import mkdir, save_config
from maskrcnn_benchmark.utils.metric_logger import MetricLogger


# See if we can use apex.DistributedDataParallel instead of the torch default,
# and enable mixed-precision via apex.amp
try:
    from apex import amp
except ImportError:
    raise ImportError('Use APEX for multi-precision via apex.amp')

# for center loss
# https://github.com/louis-she/center-loss.pytorch/blob/master/loss.py
def get_center_delta(features, centers, targets, alpha):
    # implementation equation (4) in the center-loss paper
    features = features.view(features.size(0), -1)
    targets, indices = torch.sort(targets)
    target_centers = centers[targets]
    features = features[indices]

    delta_centers = target_centers - features
    uni_targets, indices = torch.unique(
            targets.cpu(), sorted=True, return_inverse=True)

    uni_targets = uni_targets.to(features.device)
    indices = indices.to(features.device)

    delta_centers = torch.zeros(
        uni_targets.size(0), delta_centers.size(1)
    ).to(features.device).index_add_(0, indices, delta_centers)

    targets_repeat_num = uni_targets.size()[0]
    uni_targets_repeat_num = targets.size()[0]
    targets_repeat = targets.repeat(
            targets_repeat_num).view(targets_repeat_num, -1)
    uni_targets_repeat = uni_targets.unsqueeze(1).repeat(
            1, uni_targets_repeat_num)
    same_class_feature_count = torch.sum(
            targets_repeat == uni_targets_repeat, dim=1).float().unsqueeze(1)

    delta_centers = delta_centers / (same_class_feature_count + 1.0) * alpha
    result = torch.zeros_like(centers)
    result[uni_targets, :] = delta_centers
    return result

def train(cfg, local_rank, distributed, logger, writer=None):
    debug_print(logger, 'prepare training')
    model = build_detection_model(cfg) 
    debug_print(logger, 'end model construction')

    # modules that should be always set in eval mode
    # their eval() method should be called after model.train() is called
    eval_modules = (model.rpn, model.backbone, model.roi_heads.box,)
 
    fix_eval_modules(eval_modules)

    # NOTE, we slow down the LR of the layers start with the names in slow_heads
    if cfg.MODEL.ROI_RELATION_HEAD.PREDICTOR == "IMPPredictor":
        slow_heads = ["roi_heads.relation.box_feature_extractor",
                      "roi_heads.relation.union_feature_extractor.feature_extractor",]
    else:
        slow_heads = []
    # load pretrain layers to new layers
    load_mapping = {"roi_heads.relation.box_feature_extractor" : "roi_heads.box.feature_extractor",
                    "roi_heads.relation.union_feature_extractor.feature_extractor" : "roi_heads.box.feature_extractor"}
    
    if cfg.MODEL.ATTRIBUTE_ON:
        load_mapping["roi_heads.relation.att_feature_extractor"] = "roi_heads.attribute.feature_extractor"
        load_mapping["roi_heads.relation.union_feature_extractor.att_feature_extractor"] = "roi_heads.attribute.feature_extractor"


    device = torch.device(cfg.MODEL.DEVICE)
    model.to(device)

    num_gpus = int(os.environ["WORLD_SIZE"]) if "WORLD_SIZE" in os.environ else 1
    num_batch = cfg.SOLVER.IMS_PER_BATCH
    optimizer = make_optimizer(cfg, model, logger, slow_heads=slow_heads, slow_ratio=10.0, rl_factor=float(num_batch))
    scheduler = make_lr_scheduler(cfg, optimizer, logger)
    debug_print(logger, 'end optimizer and shcedule')
    # Initialize mixed-precision training
    use_mixed_precision = cfg.DTYPE == "float16"
    amp_opt_level = 'O1' if use_mixed_precision else 'O0'
    model, optimizer = amp.initialize(model, optimizer, opt_level=amp_opt_level)
    if distributed:
        model = torch.nn.parallel.DistributedDataParallel(
            model, device_ids=[local_rank], output_device=local_rank,
            # this should be removed if we update BatchNorm stats
            broadcast_buffers=False,
            find_unused_parameters=True,
        )
    debug_print(logger, 'end distributed')
    arguments = {}
    arguments["iteration"] = 0
    output_dir = cfg.OUTPUT_DIR

    save_to_disk = get_rank() == 0
    checkpointer = DetectronCheckpointer(
        cfg, model, optimizer, scheduler, output_dir, save_to_disk, custom_scheduler=True
    )
    # if there is certain checkpoint in output_dir, load it, else load pretrained detector
    if checkpointer.has_checkpoint():
        extra_checkpoint_data = checkpointer.load(cfg.MODEL.PRETRAINED_DETECTOR_CKPT, 
                                       update_schedule=cfg.SOLVER.UPDATE_SCHEDULE_DURING_LOAD)
        arguments.update(extra_checkpoint_data)
    else:
        # load_mapping is only used when we init current model from detection model.
        checkpointer.load(cfg.MODEL.PRETRAINED_DETECTOR_CKPT, with_optim=False, load_mapping=load_mapping)
    debug_print(logger, 'end load checkpointer')
    train_data_loader = make_data_loader(
        cfg,
        mode='train',
        is_distributed=distributed,
        start_iter=arguments["iteration"],
    )
    val_data_loaders = make_data_loader(
        cfg,
        mode='val',
        is_distributed=distributed,
    )
    debug_print(logger, 'end dataloader')
    checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD
    #if cfg.SOLVER.PRE_VAL:
    #    logger.info("Validate before training")
    #    run_val(cfg, model, val_data_loaders, distributed, logger)

    logger.info("Start training")
    meters = MetricLogger(delimiter="  ")
    max_iter = len(train_data_loader)
    start_iter = arguments["iteration"]
    start_training_time = time.time()
    end = time.time()

    vg_root = 'datasets/vg'
    vg_dict_path = os.path.join(vg_root, 'VG-SGG-dicts-with-attri.json')
    with open(vg_dict_path, 'r') as f:
        vg_dict = json.load(f)
    print_first_grad = True

    for iteration, (images, targets, _) in enumerate(train_data_loader, start_iter):
        if any(len(target) < 1 for target in targets):
            logger.error(f"Iteration={iteration + 1} || Image Ids used for training {_} || targets Length={[len(target) for target in targets]}" )
        data_time = time.time() - end
        iteration = iteration + 1      
        arguments["iteration"] = iteration

        model.train()
        fix_eval_modules(eval_modules)
        #images = torch.tensor(images)

        images = images.to(device)
        targets = [target.to(device) for target in targets]

        loss_dict, rel_features, rel_targets = model(images, targets)

        # if cfg.MODEL.PCPL_CENTER_LOSS:
        #     losses = sum(loss for loss_name, loss in loss_dict.items() if loss_name != 'loss_center')
        #     losses += loss_dict['loss_center'] * cfg.MODEL.CENTER_LOSS_ALPHA
        # else:
        #     losses = sum(loss for loss in loss_dict.values())
        if cfg.MODEL.BALANCED_NORM_TRAIN_GX:
            assert not cfg.MODEL.TRAIN_AVG_BELIEF_TO_ONE # HAVEN'T IMPLEMENTED TO RUN TOGETHER
            alpha = cfg.MODEL.BALANCED_NORM_TRAIN_GX_LOSS_ALPHA
            losses = sum(loss if loss_name != 'loss_gx' else loss * alpha for loss_name, loss in loss_dict.items())
        elif cfg.MODEL.TRAIN_AVG_BELIEF_TO_ONE and not cfg.MODEL.TRAIN_AVG_BELIEF_TO_ONE_ONLY_THIS_LOSS:
            factor = cfg.MODEL.TRAIN_AVG_BELIEF_TO_ONE_FACTOR
            losses = sum(loss if loss_name != 'loss_avg_belief' else loss * factor for loss_name, loss in loss_dict.items())
        else:
            # losses = sum(loss for loss in loss_dict.values())
            losses = sum(loss for key, loss in loss_dict.items() if key != 'rel_labels_one_hot_count')
        # reduce losses over all GPUs for logging purposes
        # import pdb; pdb.set_trace()
        loss_dict_reduced = reduce_loss_dict(loss_dict)
        # losses_reduced = sum(loss for loss in loss_dict_reduced.values())
        losses_reduced = sum(loss for key, loss in loss_dict_reduced.items() if key != 'rel_labels_one_hot_count')
        meters.update(loss=losses_reduced, **loss_dict_reduced)
        

        optimizer.zero_grad()
        # Note: If mixed precision is not used, this ends up doing nothing
        # Otherwise apply loss scaling for mixed-precision recipe
        with amp.scale_loss(losses, optimizer) as scaled_losses:
            scaled_losses.backward()
        
        # Center Loss version 1: https://github.com/KaiyangZhou/pytorch-center-loss
        # if cfg.MODEL.PCPL_CENTER_LOSS:
        #     for param in model.roi_heads.relation.loss_evaluator.center_loss.parameters():
        #         # lr_cent is learning rate for center loss, e.g. lr_cent = 0.5
        #         param.grad.data *= (cfg.MODEL.CENTER_LOSS_LR / (cfg.MODEL.CENTER_LOSS_ALPHA * cfg.SOLVER.BASE_LR))
        
        # add clip_grad_norm from MOTIFS, tracking gradient, used for debug
        verbose = (iteration % cfg.SOLVER.PRINT_GRAD_FREQ) == 0 or print_first_grad # print grad or not
        print_first_grad = False
        clip_grad_norm([(n, p) for n, p in model.named_parameters() if p.requires_grad], max_norm=cfg.SOLVER.GRAD_NORM_CLIP, logger=logger, verbose=verbose, clip=True)

        optimizer.step()

        # Center Loss version 2
        if cfg.MODEL.PCPL_CENTER_LOSS:
            # import pdb; pdb.set_trace()
            alpha = cfg.MODEL.CENTER_LOSS_ALPHA
            centers = model.module.roi_heads.relation.loss_evaluator.centers.detach()
            center_deltas = get_center_delta(rel_features, centers, rel_targets, alpha)
            model.module.roi_heads.relation.loss_evaluator.centers = centers - center_deltas

        batch_time = time.time() - end
        end = time.time()
        meters.update(time=batch_time, data=data_time)

        eta_seconds = meters.time.global_avg * (max_iter - iteration)
        eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))


        if iteration % cfg.SOLVER.RECORD_PERIOD == 0 or iteration == max_iter:
            logger.info(
                meters.delimiter.join(
                    [
                        "eta: {eta}",
                        "iter: {iter}",
                        "{meters}",
                        "lr: {lr:.6f}",
                        "max mem: {memory:.0f}",
                    ]
                ).format(
                    eta=eta_string,
                    iter=iteration,
                    meters=str(meters),
                    lr=optimizer.param_groups[-1]["lr"],
                    memory=torch.cuda.max_memory_allocated() / 1024.0 / 1024.0,
                )
            )
            if cfg.LOG_TB and writer is not None:
                # assert writer is not None
                for name, meter in meters.meters.items():
                    if name == 'rel_labels_one_hot_count':
                        selected_predicates = [
                                'on', 'has', 'wearing', 'of', 'in', 'near', 'behind', 'with', 'holding', 'above', 
                                'sitting on', 'wears', 'under', 'riding', 'in front of', 'standing on', 'at', 'attached to', 'carrying', 'walking on', 
                                'over', 'for', 'looking at', 'watching', 'hanging from', 'parked on', 'laying on', 'belonging to', 'eating', 'and', 
                                'using', 'covering', 'between', 'along', 'covered in', 'part of', 'lying on', 'on back of', 'to', 'walking in', 
                                'mounted on', 'across', 'against', 'from', 'growing on', 'painted on', 'playing', 'made of', 'flying in', 'says'
                            ]
                        predicate_to_idx = {predicate:idx for idx, predicate in vg_dict['idx_to_predicate'].items()}
                        for pred in selected_predicates:
                            # import pdb; pdb.set_trace()
                            writer.add_scalar(f'Label_Freq_Examples_total/{pred}', meter.total[int(predicate_to_idx[pred])], iteration)
                            writer.add_scalar(f'Label_Freq_Examples_avg/{pred}', meter.global_avg[int(predicate_to_idx[pred])], iteration)
                    else:
                        writer.add_scalar(f'Train/{name}', meter.global_avg, iteration)


        if iteration % checkpoint_period == 0:
            checkpointer.save("model_{:07d}".format(iteration), **arguments)
        if iteration == max_iter:
            checkpointer.save("model_final", **arguments)

        val_result = None # used for scheduler updating
        if cfg.SOLVER.TO_VAL and iteration % cfg.SOLVER.VAL_PERIOD == 0:
            logger.info("Start validating")
            val_result = run_val(cfg, model, val_data_loaders, distributed, logger)
            logger.info("Validation Result: %.4f" % val_result)
            if cfg.LOG_TB and writer is not None:
                metric_name = 'Val/mR_100' if cfg.TRAIN.MONITOR_MEAN_RECALL else 'Val/Recall_100'
                writer.add_scalar(metric_name, val_result, iteration)
 
        # scheduler should be called after optimizer.step() in pytorch>=1.1.0
        # https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
        if cfg.SOLVER.SCHEDULE.TYPE == "WarmupReduceLROnPlateau":
            scheduler.step(val_result, epoch=iteration)
            #if scheduler.stage_count >= cfg.SOLVER.SCHEDULE.MAX_DECAY_STEP:
            #    logger.info("Trigger MAX_DECAY_STEP at iteration {}.".format(iteration))
            #    break
        else:
            scheduler.step()

    total_training_time = time.time() - start_training_time
    total_time_str = str(datetime.timedelta(seconds=total_training_time))
    logger.info(
        "Total training time: {} ({:.4f} s / it)".format(
            total_time_str, total_training_time / (max_iter)
        )
    )
    return model

def fix_eval_modules(eval_modules):
    for module in eval_modules:
        for _, param in module.named_parameters():
            param.requires_grad = False
        # DO NOT use module.eval(), otherwise the module will be in the test mode, i.e., all self.training condition is set to False

def run_val(cfg, model, val_data_loaders, distributed, logger):
    if distributed:
        model = model.module
    torch.cuda.empty_cache()
    iou_types = ("bbox",)
    if cfg.MODEL.MASK_ON:
        iou_types = iou_types + ("segm",)
    if cfg.MODEL.KEYPOINT_ON:
        iou_types = iou_types + ("keypoints",)
    if cfg.MODEL.RELATION_ON:
        iou_types = iou_types + ("relations", )
    if cfg.MODEL.ATTRIBUTE_ON:
        iou_types = iou_types + ("attributes", )

    dataset_names = cfg.DATASETS.VAL
    val_result = []
    for dataset_name, val_data_loader in zip(dataset_names, val_data_loaders):
        dataset_result = inference(
                            cfg,
                            model,
                            val_data_loader,
                            dataset_name=dataset_name,
                            iou_types=iou_types,
                            box_only=False if cfg.MODEL.RETINANET_ON else cfg.MODEL.RPN_ONLY,
                            device=cfg.MODEL.DEVICE,
                            expected_results=cfg.TEST.EXPECTED_RESULTS,
                            expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,
                            output_folder=None,
                            logger=logger,
                        )
        synchronize()
        val_result.append(dataset_result)
    # support for multi gpu distributed testing
    gathered_result = all_gather(torch.tensor(dataset_result).cpu())
    gathered_result = [t.view(-1) for t in gathered_result]
    gathered_result = torch.cat(gathered_result, dim=-1).view(-1)
    valid_result = gathered_result[gathered_result>=0]
    val_result = float(valid_result.mean())
    del gathered_result, valid_result
    torch.cuda.empty_cache()
    return val_result

def run_test(cfg, model, distributed, logger):
    if distributed:
        model = model.module
    torch.cuda.empty_cache()
    iou_types = ("bbox",)
    if cfg.MODEL.MASK_ON:
        iou_types = iou_types + ("segm",)
    if cfg.MODEL.KEYPOINT_ON:
        iou_types = iou_types + ("keypoints",)
    if cfg.MODEL.RELATION_ON:
        iou_types = iou_types + ("relations", )
    if cfg.MODEL.ATTRIBUTE_ON:
        iou_types = iou_types + ("attributes", )
    output_folders = [None] * len(cfg.DATASETS.TEST)
    dataset_names = cfg.DATASETS.TEST
    if cfg.OUTPUT_DIR:
        for idx, dataset_name in enumerate(dataset_names):
            output_folder = os.path.join(cfg.OUTPUT_DIR, "inference", dataset_name)
            mkdir(output_folder)
            output_folders[idx] = output_folder
    data_loaders_val = make_data_loader(cfg, mode='test', is_distributed=distributed)
    for output_folder, dataset_name, data_loader_val in zip(output_folders, dataset_names, data_loaders_val):
        inference(
            cfg,
            model,
            data_loader_val,
            dataset_name=dataset_name,
            iou_types=iou_types,
            box_only=False if cfg.MODEL.RETINANET_ON else cfg.MODEL.RPN_ONLY,
            device=cfg.MODEL.DEVICE,
            expected_results=cfg.TEST.EXPECTED_RESULTS,
            expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,
            output_folder=output_folder,
            logger=logger,
        )
        synchronize()
    torch.cuda.empty_cache()

def main():
    parser = argparse.ArgumentParser(description="PyTorch Relation Detection Training")
    parser.add_argument(
        "--config-file",
        default="configs/e2e_relation_X_101_32_8_FPN_1x.yaml",
        metavar="FILE",
        help="path to config file",
        type=str,
    )
    parser.add_argument("--local_rank", type=int, default=0)
    parser.add_argument(
        "--skip-test",
        dest="skip_test",
        help="Do not test the final model",
        action="store_true",
    )
    parser.add_argument(
        "opts",
        help="Modify config options using the command-line",
        default=None,
        nargs=argparse.REMAINDER,
    )
    args = parser.parse_args()

    num_gpus = int(os.environ["WORLD_SIZE"]) if "WORLD_SIZE" in os.environ else 1
    args.distributed = num_gpus > 1
    if args.distributed:
        torch.cuda.set_device(args.local_rank)
        torch.distributed.init_process_group(
            backend="nccl", init_method="env://"
        )
        synchronize()

    cfg.merge_from_file(args.config_file)
    cfg.merge_from_list(args.opts)
    """
     cfg.merge_from_list(args.opts)
    cfg.MODEL.ROI_RELATION_HEAD.USE_GT_BOX = True 
    cfg.MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL = True 
    cfg.MODEL.ROI_RELATION_HEAD.PREDICTOR = "MotifPredictor "
    cfg.SOLVER.IMS_PER_BATCH = "48 "
    cfg.TEST.IMS_PER_BATCH = "2 "
    cfg.DTYPE = "float16" 
    cfg.SOLVER.MAX_ITER = "50000 "
    cfg.SOLVER.VAL_PERIOD = "2000 "
    cfg.SOLVER.CHECKPOINT_PERIOD = "2000 "
    cfg.GLOVE_DIR = "glove "
    cfg.MODEL.PRETRAINED_DETECTOR_CKPT = "checkpoints/pretrained_faster_rcnn/model_final.pth "
    cfg.OUTPUT_DIR = "output/motif-precls-exmp "
    cfg.SOLVER.PRE_VAL = True
    """

    cfg.freeze()

    # use Tensorboard
    writer = None
    if cfg.LOG_TB and args.local_rank == 0:
        exmp_name = cfg.OUTPUT_DIR.split('/')[-1]
        writer = SummaryWriter(comment=exmp_name)

    output_dir = cfg.OUTPUT_DIR
    if output_dir:
        mkdir(output_dir)

    logger = setup_logger("maskrcnn_benchmark", output_dir, get_rank())
    logger.info("Using {} GPUs".format(num_gpus))
    logger.info(args)

    logger.info("Collecting env info (might take some time)")
    logger.info("\n" + collect_env_info())

    logger.info("Loaded configuration file {}".format(args.config_file))
    with open(args.config_file, "r") as cf:
        config_str = "\n" + cf.read()
        logger.info(config_str)
    logger.info("Running with config:\n{}".format(cfg))

    output_config_path = os.path.join(cfg.OUTPUT_DIR, 'config.yml')
    logger.info("Saving config into: {}".format(output_config_path))
    # save overloaded model config in the output directory
    save_config(cfg, output_config_path)

    model = train(cfg, args.local_rank, args.distributed, logger, writer=writer)

    if not args.skip_test:
        run_test(cfg, model, args.distributed, logger)

    if cfg.LOG_TB and args.local_rank == 0:
        writer.close()

if __name__ == "__main__":
    main()




"""
                "--nproc_per_node=2",
                "tools/relation_train_net.py",
                " --config-file=configs/e2e_relation_X_101_32_8_FPN_1x.yaml",
                "MODEL.ROI_RELATION_HEAD.USE_GT_BOX=True",
                "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL=True",
                "MODEL.ROI_RELATION_HEAD.PREDICTOR=MotifPredictor",
                "SOLVER.IMS_PER_BATCH=48",
                "TEST.IMS_PER_BATCH=2",
                "DTYPE=float16",
                "SOLVER.MAX_ITER=50000",
                "SOLVER.VAL_PERIOD=2000" ,
                "SOLVER.CHECKPOINT_PERIOD=2000",
                "GLOVE_DIR=glove",
                "MODEL.PRETRAINED_DETECTOR_CKPT=checkpoints/pretrained_faster_rcnn/model_final.pth",
                "OUTPUT_DIR=output/motif-precls-exmp",
                "SOLVER.PRE_VAL=True",
"""